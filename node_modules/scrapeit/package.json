{
  "name": "scrapeit",
  "version": "0.0.2",
  "description": "Scrape webpages with ease (htmlparser+soupselect+request)",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "dependencies": {
    "soupselect": "*",
    "request": "*",
    "htmlparser": "*"
  },
  "repository": {
    "type": "git",
    "url": "git@github.com:jb55/node-scrapeit.git"
  },
  "keywords": [
    "scrape",
    "soupselect",
    "beautifulsoup",
    "htmlparser"
  ],
  "author": {
    "name": "Bill Casarin"
  },
  "license": "MIT",
  "readme": "\n# node-scrapeit\n\nDon't think. Scrape.\n\nSimple boilerplate for soupselect + htmlparser + request.\n\n## Look how easy this is\n\n```js\nvar scrape = require('scrapeit')\n\nscrape(\"http://google.com\", function(err, o, dom){\n  o(\"p\").forEach(function(p){\n    // scrape all p tags\n  });\n});\n```\n",
  "readmeFilename": "Readme.md",
  "_id": "scrapeit@0.0.2",
  "dist": {
    "shasum": "a6c14d3ef628a54b132213ac84ea8bcfaf9eea26",
    "tarball": "https://registry.npmjs.org/scrapeit/-/scrapeit-0.0.2.tgz"
  },
  "_from": "scrapeit@0.0.2",
  "_npmVersion": "1.2.11",
  "_npmUser": {
    "name": "jb55",
    "email": "bill@casarin.ca"
  },
  "maintainers": [
    {
      "name": "jb55",
      "email": "bill@casarin.ca"
    }
  ],
  "directories": {},
  "_shasum": "a6c14d3ef628a54b132213ac84ea8bcfaf9eea26",
  "_resolved": "https://registry.npmjs.org/scrapeit/-/scrapeit-0.0.2.tgz"
}
